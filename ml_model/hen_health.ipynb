{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cd5d59",
   "metadata": {},
   "source": [
    "\t\n",
    "## Poultry Audio Classification with Deep Learning and Burn Layer Fusion\n",
    "\n",
    "This notebook implements a deep learning-based approach for classifying poultry audio signals, inspired by the paper \"Optimizing poultry audio signal classification with deep learning and burn layer fusion\".\n",
    "\n",
    "The model uses a custom Burn Layer to enhance robustness by injecting controlled random noise during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea883d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc3a8c",
   "metadata": {},
   "source": [
    "## Custom Burn Layer Implementation\n",
    "\n",
    "The Burn Layer is a key innovation from the paper that adds controlled random noise during training to improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e889cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurnLayer(layers.Layer):\n",
    "    def __init__(self, burn_intensity=0.2, **kwargs):\n",
    "        super(BurnLayer, self).__init__(**kwargs)\n",
    "        self.burn_intensity = burn_intensity\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        if training:\n",
    "\n",
    "            return inputs + self.burn_intensity * tf.random.normal(shape=tf.shape(inputs))\n",
    "        else:\n",
    "\n",
    "            return inputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(BurnLayer, self).get_config()\n",
    "        config.update({\"burn_intensity\": self.burn_intensity})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fefef",
   "metadata": {},
   "source": [
    "## Audio Feature Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee55f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Extract audio features from a file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file with specified sample rate and duration\n",
    "        y, sr = librosa.load(audio_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # If audio is shorter than duration, pad it\n",
    "        if len(y) < int(duration * sr):\n",
    "            y = np.pad(y, (0, int(duration * sr) - len(y)))\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # Extract chromagram\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        \n",
    "        # Extract spectral contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        \n",
    "        # Calculate Melspectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return y, sr, mfccs, mel_spec_db, chroma, contrast\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_path}: {e}\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "def load_and_preprocess_data(data_path, sr=44100, duration=2.0, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Load and preprocess all audio files in the dataset\n",
    "    \"\"\"\n",
    "    X_mel = []\n",
    "    y = []\n",
    "    file_paths = []\n",
    "    classes = ['Healthy', 'Noise', 'Unhealthy']\n",
    "    class_counts = {}\n",
    "    \n",
    "    for i, category in enumerate(classes):\n",
    "        path = os.path.join(data_path, category)\n",
    "        print(f\"Loading {category} samples...\")\n",
    "        count = 0\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            if not filename.lower().endswith('.wav'):\n",
    "                continue\n",
    "                \n",
    "            file_path = os.path.join(path, filename)\n",
    "            _, _, _, mel_spec_db, _, _ = extract_features(file_path, sr=sr, duration=duration, n_mfcc=n_mfcc)\n",
    "            \n",
    "            if mel_spec_db is not None:\n",
    "                X_mel.append(mel_spec_db)\n",
    "                y.append(i)\n",
    "                file_paths.append(file_path)\n",
    "                count += 1\n",
    "        \n",
    "        class_counts[category] = count\n",
    "        print(f\"  Loaded {count} samples for {category}\")\n",
    "    \n",
    "    X_mel = np.array(X_mel)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Reshape mel spectrograms for CNN input\n",
    "    X_mel = X_mel.reshape(X_mel.shape[0], X_mel.shape[1], X_mel.shape[2], 1)\n",
    "    \n",
    "    return X_mel, y, file_paths, class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b684f",
   "metadata": {},
   "source": [
    "## Data Augmentation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8230da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X_mel, y, augmentation_factor=2):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on mel spectrograms\n",
    "    \"\"\"\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    \n",
    "    # First include all original samples\n",
    "    for i in range(len(X_mel)):\n",
    "        X_aug.append(X_mel[i])\n",
    "        y_aug.append(y[i])\n",
    "    \n",
    "    # Then create augmented versions\n",
    "    for i in range(len(X_mel)):\n",
    "        mel_spec = X_mel[i].squeeze()\n",
    "        \n",
    "        # Create augmentation_factor-1 augmented versions\n",
    "        for _ in range(augmentation_factor - 1):\n",
    "            aug_mel_spec = mel_spec.copy()\n",
    "            \n",
    "            # Add random noise\n",
    "            noise_factor = np.random.uniform(0.005, 0.02)\n",
    "            noise = np.random.normal(0, noise_factor, aug_mel_spec.shape)\n",
    "            aug_mel_spec = aug_mel_spec + noise\n",
    "            \n",
    "            # Shift in time (roll)\n",
    "            shift_amount = np.random.randint(-10, 10)\n",
    "            aug_mel_spec = np.roll(aug_mel_spec, shift_amount, axis=1)\n",
    "            \n",
    "            # Frequency masking (mask random frequency bands)\n",
    "            if np.random.random() > 0.5:\n",
    "                num_masks = np.random.randint(1, 3)\n",
    "                for _ in range(num_masks):\n",
    "                    f0 = np.random.randint(0, aug_mel_spec.shape[0] - 5)\n",
    "                    f_width = np.random.randint(1, 5)\n",
    "                    aug_mel_spec[f0:f0+f_width, :] = aug_mel_spec.min()\n",
    "            \n",
    "            # Time masking (mask random time segments)\n",
    "            if np.random.random() > 0.5:\n",
    "                num_masks = np.random.randint(1, 3)\n",
    "                for _ in range(num_masks):\n",
    "                    t0 = np.random.randint(0, aug_mel_spec.shape[1] - 5)\n",
    "                    t_width = np.random.randint(1, 5)\n",
    "                    aug_mel_spec[:, t0:t0+t_width] = aug_mel_spec.min()\n",
    "            \n",
    "            # Ensure values are valid\n",
    "            aug_mel_spec = np.clip(aug_mel_spec, -80, 0)\n",
    "            \n",
    "            # Add to augmented data\n",
    "            X_aug.append(aug_mel_spec.reshape(X_mel[i].shape))\n",
    "            y_aug.append(y[i])\n",
    "    \n",
    "    return np.array(X_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db6941",
   "metadata": {},
   "source": [
    "## Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1666e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(file_path, sr=44100, duration=2.0):\n",
    "    \"\"\"\n",
    "    Visualize audio file with waveform, MFCC, and Mel Spectrogram\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    y, sr, mfccs, mel_spec_db, chroma, contrast = extract_features(file_path, sr=sr, duration=duration)\n",
    "    \n",
    "    if y is None:\n",
    "        print(f\"Could not load audio file: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with 4 subplots\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot waveform\n",
    "    plt.subplot(4, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "    \n",
    "    # Plot MFCC\n",
    "    plt.subplot(4, 1, 2)\n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('MFCCs')\n",
    "    \n",
    "    # Plot Mel Spectrogram\n",
    "    plt.subplot(4, 1, 3)\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    \n",
    "    # Plot Chromagram\n",
    "    plt.subplot(4, 1, 4)\n",
    "    librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma')\n",
    "    plt.colorbar()\n",
    "    plt.title('Chromagram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_augmentation(X_mel, index, augmentation_factor=3):\n",
    "    \"\"\"\n",
    "    Visualize original and augmented mel spectrograms\n",
    "    \"\"\"\n",
    "    # Get original mel spectrogram\n",
    "    original_mel = X_mel[index].squeeze()\n",
    "    \n",
    "    # Create augmented versions\n",
    "    augmented_mels = []\n",
    "    for _ in range(augmentation_factor):\n",
    "        aug_mel = original_mel.copy()\n",
    "        \n",
    "        # Add random noise\n",
    "        noise_factor = np.random.uniform(0.005, 0.02)\n",
    "        noise = np.random.normal(0, noise_factor, aug_mel.shape)\n",
    "        aug_mel = aug_mel + noise\n",
    "        \n",
    "        # Shift in time (roll)\n",
    "        shift_amount = np.random.randint(-10, 10)\n",
    "        aug_mel = np.roll(aug_mel, shift_amount, axis=1)\n",
    "        \n",
    "        # Frequency masking\n",
    "        if np.random.random() > 0.5:\n",
    "            f0 = np.random.randint(0, aug_mel.shape[0] - 5)\n",
    "            f_width = np.random.randint(1, 5)\n",
    "            aug_mel[f0:f0+f_width, :] = aug_mel.min()\n",
    "        \n",
    "        # Time masking\n",
    "        if np.random.random() > 0.5:\n",
    "            t0 = np.random.randint(0, aug_mel.shape[1] - 5)\n",
    "            t_width = np.random.randint(1, 5)\n",
    "            aug_mel[:, t0:t0+t_width] = aug_mel.min()\n",
    "        \n",
    "        augmented_mels.append(aug_mel)\n",
    "    \n",
    "    # Visualize original and augmented spectrograms\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original\n",
    "    plt.subplot(2, 2, 1)\n",
    "    librosa.display.specshow(original_mel, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Original Mel Spectrogram')\n",
    "    \n",
    "    # Augmented versions\n",
    "    for i, aug_mel in enumerate(augmented_mels):\n",
    "        plt.subplot(2, 2, i+2)\n",
    "        librosa.display.specshow(aug_mel, x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(f'Augmented Version {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deb4d7",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "This model implements the architecture described in the paper, with convolutional blocks, Burn Layer and global average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61283035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_burn_model(input_shape, num_classes=3):\n",
    "    \"\"\"\n",
    "    Build the model with Burn Layer as described in the paper\n",
    "    \"\"\"\n",
    "    # Input tensor\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Apply initial Burn Layer to input\n",
    "    x = BurnLayer(burn_intensity=0.2)(inputs)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Global average pooling to create a fusion layer\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layer\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    \n",
    "    # Second Burn Layer with reduced intensity\n",
    "    x = BurnLayer(burn_intensity=0.1)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile with Adamax optimizer as used in the paper\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adamax(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bf0b0",
   "metadata": {},
   "source": [
    "## Training Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping and model checkpointing\n",
    "    \"\"\"\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'best_poultry_audio_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def k_fold_cross_validation(X, y, n_splits=5, epochs=50, batch_size=16):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nTraining Fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_burn_model(input_shape=X_train.shape[1:], num_classes=len(np.unique(y)))\n",
    "        history = train_model(model, X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "        \n",
    "        # Evaluate model\n",
    "        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_results.append((val_loss, val_acc))\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Calculate average results\n",
    "    avg_loss = np.mean([res[0] for res in fold_results])\n",
    "    avg_acc = np.mean([res[1] for res in fold_results])\n",
    "    std_acc = np.std([res[1] for res in fold_results])\n",
    "    \n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"Average Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Average Validation Accuracy: {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    \n",
    "    return fold_results, avg_acc, std_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f863b",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e10e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, class_names):\n",
    "    \"\"\"\n",
    "    Evaluate the model and calculate metrics mentioned in the paper\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes, target_names=class_names))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=class_names,\n",
    "               yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics mentioned in the paper\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    # Initialize arrays for metrics\n",
    "    sensitivity = np.zeros(n_classes)\n",
    "    specificity = np.zeros(n_classes)\n",
    "    precision = np.zeros(n_classes)\n",
    "    npv = np.zeros(n_classes)\n",
    "    f1 = np.zeros(n_classes)\n",
    "    mcc = np.zeros(n_classes)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    for i in range(n_classes):\n",
    "        # True positives, false positives, true negatives, false negatives\n",
    "        TP = cm[i, i]\n",
    "        FP = np.sum(cm[:, i]) - TP\n",
    "        FN = np.sum(cm[i, :]) - TP\n",
    "        TN = np.sum(cm) - (TP + FP + FN)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sensitivity[i] = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        specificity[i] = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        precision[i] = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        npv[i] = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "        \n",
    "        # F1 score\n",
    "        f1[i] = 2 * (precision[i] * sensitivity[i]) / (precision[i] + sensitivity[i]) if (precision[i] + sensitivity[i]) > 0 else 0\n",
    "        \n",
    "        # Matthews Correlation Coefficient\n",
    "        mcc_numerator = (TP * TN - FP * FN)\n",
    "        mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) > 0 else 1\n",
    "        mcc[i] = mcc_numerator / mcc_denominator\n",
    "    \n",
    "    # Print per-class metrics\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    for i in range(n_classes):\n",
    "        print(f\"\\n{class_names[i]}:\")\n",
    "        print(f\"  Sensitivity: {sensitivity[i] * 100:.2f}%\")\n",
    "        print(f\"  Specificity: {specificity[i] * 100:.2f}%\")\n",
    "        print(f\"  Precision: {precision[i] * 100:.2f}%\")\n",
    "        print(f\"  NPV: {npv[i] * 100:.2f}%\")\n",
    "        print(f\"  F1 Score: {f1[i] * 100:.2f}%\")\n",
    "        print(f\"  MCC: {mcc[i] * 100:.2f}%\")\n",
    "    \n",
    "    # Average metrics\n",
    "    print(\"\\nAverage Metrics:\")\n",
    "    print(f\"  Sensitivity: {np.mean(sensitivity) * 100:.2f}%\")\n",
    "    print(f\"  Specificity: {np.mean(specificity) * 100:.2f}%\")\n",
    "    print(f\"  Precision: {np.mean(precision) * 100:.2f}%\")\n",
    "    print(f\"  NPV: {np.mean(npv) * 100:.2f}%\")\n",
    "    print(f\"  F1 Score: {np.mean(f1) * 100:.2f}%\")\n",
    "    print(f\"  MCC: {np.mean(mcc) * 100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'sensitivity': np.mean(sensitivity),\n",
    "        'specificity': np.mean(specificity),\n",
    "        'precision': np.mean(precision),\n",
    "        'npv': np.mean(npv),\n",
    "        'f1': np.mean(f1),\n",
    "        'mcc': np.mean(mcc)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043a631",
   "metadata": {},
   "source": [
    "## Prediction function for New Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfef6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(model, audio_path, sr=44100, duration=2.0, n_mfcc=20, classes=['Healthy', 'Noise', 'Unhealthy']):\n",
    "    \"\"\"\n",
    "    Predict the class of a new audio file\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    _, _, _, mel_spec_db, _, _ = extract_features(audio_path, sr=sr, duration=duration, n_mfcc=n_mfcc)\n",
    "    \n",
    "    if mel_spec_db is None:\n",
    "        print(f\"Could not process audio file: {audio_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Reshape for model input\n",
    "    mel_spec_db = mel_spec_db.reshape(1, mel_spec_db.shape[0], mel_spec_db.shape[1], 1)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(mel_spec_db)\n",
    "    pred_class = np.argmax(pred, axis=1)[0]\n",
    "    confidence = pred[0][pred_class]\n",
    "    \n",
    "    print(f\"Predicted class: {classes[pred_class]} (Confidence: {confidence * 100:.2f}%)\")\n",
    "    print(\"\\nClass probabilities:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        print(f\"  {cls}: {pred[0][i] * 100:.2f}%\")\n",
    "    \n",
    "    # Visualize the audio\n",
    "    visualize_audio(audio_path, sr=sr, duration=duration)\n",
    "    \n",
    "    return classes[pred_class], confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d05afb",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset\n",
    "data_path = 'Chicken_Audio_Dataset'\n",
    "\n",
    "# Set hyperparameters from the paper\n",
    "sr = 44100  # Sample rate\n",
    "duration = 2.0  # Duration in seconds\n",
    "n_mfcc = 20  # Number of MFCC features\n",
    "n_epochs = 50\n",
    "batch_size = 16\n",
    "classes = ['Healthy', 'Noise', 'Unhealthy']\n",
    "# Load and preprocess data\n",
    "print(\"Loading and preprocessing data...\")\n",
    "X_mel, y, file_paths, class_counts = load_and_preprocess_data(data_path, sr=sr, duration=duration, n_mfcc=n_mfcc)\n",
    "\n",
    "print(f\"\\nTotal dataset size: {len(X_mel)} samples\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"  {cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples from each class\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_indices = np.where(y == i)[0]\n",
    "    if len(class_indices) > 0:\n",
    "        sample_idx = np.random.choice(class_indices)\n",
    "        print(f\"\\nVisualizing a sample from the {class_name} class:\")\n",
    "        visualize_audio(file_paths[sample_idx], sr=sr, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data augmentation\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_indices = np.where(y == i)[0]\n",
    "    if len(class_indices) > 0:\n",
    "        sample_idx = np.random.choice(class_indices)\n",
    "        print(f\"\\nVisualizing augmentation for a {class_name} sample:\")\n",
    "        visualize_augmentation(X_mel, sample_idx, augmentation_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee890ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "print(\"\\nAugmenting training data...\")\n",
    "X_aug, y_aug = augment_data(X_mel, y, augmentation_factor=2)\n",
    "print(f\"Original dataset size: {len(X_mel)}\")\n",
    "print(f\"Augmented dataset size: {len(X_aug)}\")\n",
    "\n",
    "# Class distribution after augmentation\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"  {class_name}: {np.sum(y_aug == i)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0800f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_aug, y_aug, test_size=0.3, random_state=42, stratify=y_aug)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Print class distribution\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"Class {class_name}:\")\n",
    "    print(f\"  Training: {np.sum(y_train == i)} samples\")\n",
    "    print(f\"  Validation: {np.sum(y_val == i)} samples\")\n",
    "    print(f\"  Testing: {np.sum(y_test == i)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "print(\"\\nBuilding the model...\")\n",
    "model = build_burn_model(input_shape=X_train.shape[1:], num_classes=len(classes))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fda3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "history = train_model(model, X_train, y_train, X_val, y_val, epochs=n_epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nEvaluating the model...\")\n",
    "metrics = evaluate_model(model, X_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('poultry_audio_classifier.h5')\n",
    "print(\"Model saved as 'poultry_audio_classifier.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
